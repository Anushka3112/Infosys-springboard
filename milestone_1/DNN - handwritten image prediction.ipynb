{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "R9uckVMtR2xB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "def preprocess_mnist_style(img_path):\n",
        "    # 1Ô∏è‚É£ Load grayscale\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "    if img is None:\n",
        "        raise FileNotFoundError(f\"Image not found: {img_path}\")\n",
        "\n",
        "    # 2Ô∏è‚É£ Threshold to get binary image (black/white)\n",
        "    _, img_bin = cv2.threshold(img, 128, 255, cv2.THRESH_BINARY_INV)  # digit white, background black\n",
        "\n",
        "    # 3Ô∏è‚É£ Find bounding box of the digit\n",
        "    contours, _ = cv2.findContours(img_bin, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    if len(contours) == 0:\n",
        "        raise ValueError(\"No digit found in the image!\")\n",
        "    x, y, w, h = cv2.boundingRect(contours[0])\n",
        "    digit = img_bin[y:y+h, x:x+w]\n",
        "\n",
        "    # 4Ô∏è‚É£ Resize while keeping aspect ratio\n",
        "    # Target size: 20x20 (like MNIST)\n",
        "    h_new = 20\n",
        "    w_new = int(w * (20 / h)) if h > w else 20\n",
        "    digit_resized = cv2.resize(digit, (w_new, h_new))\n",
        "\n",
        "    # 5Ô∏è‚É£ Place in 28x28 canvas, centered\n",
        "    canvas = np.zeros((28,28), dtype=np.uint8)\n",
        "    x_offset = (28 - w_new) // 2\n",
        "    y_offset = (28 - h_new) // 2\n",
        "    canvas[y_offset:y_offset+h_new, x_offset:x_offset+w_new] = digit_resized\n",
        "\n",
        "    # 6Ô∏è‚É£ Normalize to [0,1]\n",
        "    canvas = canvas.astype(\"float32\") / 255.0\n",
        "\n",
        "    # 7Ô∏è‚É£ Flatten for DNN\n",
        "    canvas = canvas.reshape(1, 784)\n",
        "\n",
        "    return canvas\n"
      ],
      "metadata": {
        "id": "mQh34uI61fJw"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function takes an image of a handwritten digit and converts it into a MNIST-like format suitable for a DNN trained on MNIST digits.\n",
        "\n",
        "Loads the image as grayscale (single channel).\n",
        "\n",
        "Inversion (THRESH_BINARY_INV) ensures the digit matches MNIST format.\n",
        "\n",
        "canvas = np.zeros((28,28), dtype=np.uint8)\n",
        "Creates a 28x28 black canvas (MNIST size).\n",
        "\n",
        "Flattened DNNs are very sensitive to position and scale.\n",
        "\n",
        "This preprocessing makes handwritten digit look like MNIST, so the model can recognize it better.\n",
        "\n",
        "(The  handwritten image which is passed is taken from camscanner and  it is scanned and then it is preprocessed in code)"
      ],
      "metadata": {
        "id": "yvvPK7TEBJnn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = preprocess_mnist_style(\"/content/result_num (3).jpg\")\n",
        "pred = model.predict(X)\n",
        "label = np.argmax(pred)\n",
        "print(\"Predicted Digit:\", label)\n",
        "print(\"Confidence:\", np.max(pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TU_PJ3EM2W0O",
        "outputId": "4bb24f10-7da4-40a2-f8d8-fef141757ab3"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
            "Predicted Digit: 8\n",
            "Confidence: 0.9994654\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from keras.models import load_model\n",
        "\n",
        "# 1Ô∏è‚É£ Load the DNN model\n",
        "model_path = \"/content/mnist_dnn.keras\"\n",
        "model = load_model(model_path)\n",
        "print(\"‚úÖ Model loaded successfully!\")\n",
        "\n",
        "# 2Ô∏è‚É£ MNIST-style preprocessing\n",
        "def preprocess_mnist_style(img_path):\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "    if img is None:\n",
        "        raise FileNotFoundError(f\"Image not found: {img_path}\")\n",
        "\n",
        "    # Threshold & invert: digit white, background black\n",
        "    _, img_bin = cv2.threshold(img, 128, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "    # Find bounding box of digit\n",
        "    contours, _ = cv2.findContours(img_bin, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    if len(contours) == 0:\n",
        "        raise ValueError(\"No digit found in the image!\")\n",
        "    x, y, w, h = cv2.boundingRect(contours[0])\n",
        "    digit = img_bin[y:y+h, x:x+w]\n",
        "\n",
        "    # Resize keeping aspect ratio\n",
        "    h_new = 20\n",
        "    w_new = int(w * (20 / h)) if h > w else 20\n",
        "    digit_resized = cv2.resize(digit, (w_new, h_new))\n",
        "\n",
        "    # Center in 28x28 canvas\n",
        "    canvas = np.zeros((28,28), dtype=np.uint8)\n",
        "    x_offset = (28 - w_new) // 2\n",
        "    y_offset = (28 - h_new) // 2\n",
        "    canvas[y_offset:y_offset+h_new, x_offset:x_offset+w_new] = digit_resized\n",
        "\n",
        "    # Normalize & flatten\n",
        "    canvas = canvas.astype(\"float32\") / 255.0\n",
        "    canvas = canvas.reshape(1, 784)\n",
        "\n",
        "    return canvas\n",
        "\n",
        "# Preprocess your image\n",
        "X = preprocess_mnist_style(\"/content/result_num (3).jpg\")\n",
        "print(\"Input shape:\", X.shape)\n",
        "\n",
        "# 3Ô∏è‚É£ Predict digit\n",
        "pred = model.predict(X)\n",
        "label = np.argmax(pred)\n",
        "print(\"\\nüéØ Predicted Digit:\", label)\n",
        "print(\"Confidence:\", np.max(pred))\n",
        "\n",
        "# 4Ô∏è‚É£ Layer-by-layer outputs\n",
        "intermediate_outputs = []\n",
        "input_to_layer = X\n",
        "\n",
        "for i, layer in enumerate(model.layers):\n",
        "    output = layer(input_to_layer)           # call each layer manually\n",
        "    intermediate_outputs.append(output.numpy())\n",
        "    input_to_layer = output\n",
        "\n",
        "# 5Ô∏è‚É£ Print outputs\n",
        "print(\"\\nüîç LAYER-BY-LAYER OUTPUTS:\")\n",
        "for i, out in enumerate(intermediate_outputs):\n",
        "    print(f\"\\n----- Layer {i}: {model.layers[i].name} -----\")\n",
        "    print(\"Shape:\", out.shape)\n",
        "    print(out)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCmt_nn_2b_4",
        "outputId": "dd2d4d40-bd78-45ef-ba1f-de8c3b67122e"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Model loaded successfully!\n",
            "Input shape: (1, 784)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step\n",
            "\n",
            "üéØ Predicted Digit: 8\n",
            "Confidence: 0.9994654\n",
            "\n",
            "üîç LAYER-BY-LAYER OUTPUTS:\n",
            "\n",
            "----- Layer 0: dense_3 -----\n",
            "Shape: (1, 256)\n",
            "[[0.         1.9673034  0.         0.         0.         0.\n",
            "  4.397518   0.         0.         0.         0.         0.\n",
            "  0.         0.         1.5611564  0.         0.         0.\n",
            "  0.         1.7604582  0.20794944 0.         0.         0.\n",
            "  0.         0.6956392  0.78662807 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         1.480578   0.         0.         0.         1.8665639\n",
            "  0.         0.         0.23447591 0.         0.6605591  0.\n",
            "  0.         0.         0.         0.         0.71121395 0.\n",
            "  0.         0.         0.         0.         0.         2.0043712\n",
            "  0.         0.         0.         0.         0.         2.916184\n",
            "  0.20158628 0.         1.8172084  0.         0.         1.9014429\n",
            "  0.         0.         0.         1.2752706  0.5706464  0.\n",
            "  0.         0.         1.3313214  0.         0.         0.\n",
            "  0.         0.         0.         0.         0.32714003 0.\n",
            "  0.         0.         0.         0.06651266 3.221065   0.\n",
            "  1.3642074  2.0890722  0.         0.         2.643456   0.\n",
            "  0.         0.         0.         0.         0.7492422  0.\n",
            "  0.         0.         1.0324316  0.12617484 0.         1.9389584\n",
            "  0.         1.8325738  0.         1.8274633  0.05847055 0.21911603\n",
            "  2.1618226  0.         0.22068553 0.         0.         0.37970203\n",
            "  0.07034767 0.         3.597525   0.2783167  0.36834806 0.9143048\n",
            "  1.7778704  0.8098969  0.         2.2078552  0.         0.\n",
            "  0.         0.         0.         2.305546   0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.9014268  0.         0.         1.1232065  1.0709158  0.83252454\n",
            "  0.87061137 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.2787928  0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.93327576 0.         0.         0.         0.47762984\n",
            "  0.         0.         0.         0.         1.5938083  0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         1.033672   3.095678   0.36045521 0.5589503  0.\n",
            "  0.         0.8434328  0.         0.         0.12797597 0.\n",
            "  0.48531944 0.         0.         0.         0.         0.6445005\n",
            "  0.         0.         0.02168697 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.6587068  0.         0.         1.356934\n",
            "  0.         0.         3.1579275  0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         1.1008941  0.         0.\n",
            "  0.         0.         0.         0.        ]]\n",
            "\n",
            "----- Layer 1: dense_4 -----\n",
            "Shape: (1, 128)\n",
            "[[0.         2.2790465  1.3292757  0.8264629  1.0273536  0.\n",
            "  1.4161586  0.         1.1113185  0.70644814 3.4591484  1.3934376\n",
            "  0.         0.         1.466445   1.2630888  0.91366124 0.\n",
            "  3.520331   0.         0.         0.         0.         0.\n",
            "  3.9812572  2.113105   1.784051   1.8613682  0.         0.14841348\n",
            "  0.         1.0606546  0.619235   0.6344574  0.         0.\n",
            "  2.7929015  0.         0.69759786 0.58215564 0.         0.\n",
            "  0.5090602  3.2176423  0.         2.0728784  0.         0.\n",
            "  0.         0.         2.0339541  0.04441237 0.         0.\n",
            "  2.910747   1.744942   2.4565082  1.8476255  0.         0.23656291\n",
            "  0.4633232  1.6099961  0.         0.         0.         0.19512057\n",
            "  0.         2.1035328  0.         0.         1.6144257  0.\n",
            "  0.         0.11359487 0.         1.6208528  0.5890833  0.\n",
            "  0.         0.         0.5939264  0.99241924 2.587837   1.2474242\n",
            "  0.9954385  0.39891177 0.         0.12892392 0.         1.0869752\n",
            "  2.4030578  2.9298148  0.23801926 2.2130458  1.7451823  0.\n",
            "  4.093611   2.6028678  0.         0.         1.2994117  0.\n",
            "  0.         1.0628576  2.479741   0.         0.         1.0858836\n",
            "  0.73901516 0.         1.0843003  0.         0.76444006 0.95211804\n",
            "  0.18895777 0.06572683 0.         0.         0.         2.5639393\n",
            "  3.0042257  0.         2.574095   2.2482307  0.         0.23647454\n",
            "  2.555232   0.81834805]]\n",
            "\n",
            "----- Layer 2: dense_5 -----\n",
            "Shape: (1, 64)\n",
            "[[0.         0.12997964 0.         1.2606367  5.1714354  0.\n",
            "  0.39356056 0.         4.575831   4.252085   0.         0.\n",
            "  1.0994053  3.1588306  2.4708822  1.5734655  0.         0.\n",
            "  1.5523754  0.         2.792502   2.9146957  2.3455837  5.4646487\n",
            "  0.         4.9026523  1.1749837  3.844464   3.567106   0.7082087\n",
            "  2.1055977  4.537869   0.         0.         2.3998337  1.772917\n",
            "  0.         0.         4.430786   0.         0.         2.0149145\n",
            "  0.7591338  0.         0.         3.1424985  4.647684   0.\n",
            "  0.         5.036975   3.4095395  0.         0.         3.0909054\n",
            "  0.         3.2428842  2.9492853  0.         0.         4.3908286\n",
            "  5.32564    2.0820856  0.9736444  5.53011   ]]\n",
            "\n",
            "----- Layer 3: dense_6 -----\n",
            "Shape: (1, 10)\n",
            "[[9.1689071e-05 2.6444768e-06 1.4746669e-05 2.2053940e-04 9.0432350e-06\n",
            "  2.8339498e-05 4.4497926e-07 1.2955083e-07 9.9946541e-01 1.6709234e-04]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loads the pre-trained MNIST DNN model (mnist_dnn.keras).\n",
        "\n",
        "This model was trained on flattened 28√ó28 MNIST digits (784 input features).\n",
        "\n",
        "Prediction depends entirely on how close your input resembles MNIST digits.\n",
        "\n",
        "_, img_bin = cv2.threshold(img, 128, 255, cv2.THRESH_BINARY_INV) : Converts to binary (0 or 255).\n",
        "Inverts so digit = white, background = black.\n",
        "(Focuses only on the digit, removes empty background.)\n",
        "\n",
        "Converts pixel values to [0,1] (DNN expects normalized input).\n",
        "\n",
        "np.argmax(pred) selects the digit with highest probability.\n",
        "\n",
        "Example:\n",
        "\n",
        "Predicted Digit: 8\n",
        "\n",
        "Confidence: 0.98\n",
        "\n",
        "Why the model predicted this value:\n",
        "\n",
        "Your input digit looked most similar to 8 in the model‚Äôs learned feature space.\n",
        "\n",
        "Flattened DNNs are sensitive to input style.\n",
        "\n",
        "Preprocessing mismatch\n",
        "\n",
        "If the digit wasn‚Äôt perfectly centered or inverted, some features might resemble another number.\n",
        "\n",
        "MNIST-trained DNN limitations\n",
        "\n",
        " handwritten digit looks different at the pixel level than the MNIST digits the model saw during training, so the DNN predicts the closest-looking digit in its learned pixel patterns.\n",
        "   \n",
        "\n",
        "   \n",
        "\n"
      ],
      "metadata": {
        "id": "7jFruMbs9fUq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vVfRD3F_MYlB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}